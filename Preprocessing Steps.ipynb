{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam_ham_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lowered'] = df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "\n",
    "df['text_punctuationfree'] = df['text_lowered'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_punctuationfree'] = df['text_punctuationfree'].apply(lambda x: re.split(r\"\\s+\", x))\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    output = [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "\n",
    "df['text_stopwordfree'] = df['text_punctuationfree'].apply(lambda x: remove_stopwords(x))\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "df['text_stem']= df['text_stopwordfree'].apply(lambda x: [ps.stem(word) for word in x])\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "df['text_lemm'] = df['text_stopwordfree'].apply(lambda x: [lemm.lemmatize(word) for word in x])\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>text_lowered</th>\n",
       "      <th>text_punctuationfree</th>\n",
       "      <th>text_stopwordfree</th>\n",
       "      <th>text_stem</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>[subject, enron, methanol, meter, 988291, this...</td>\n",
       "      <td>[subject, enron, methanol, meter, 988291, foll...</td>\n",
       "      <td>subject enron methanol meter 988291 follow not...</td>\n",
       "      <td>subject enron methanol meter 988291 follow not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>[subject, hpl, nom, for, january, 9, 2001, see...</td>\n",
       "      <td>[subject, hpl, nom, january, 9, 2001, see, att...</td>\n",
       "      <td>subject hpl nom januari 9 2001 see attach file...</td>\n",
       "      <td>subject hpl nom january 9 2001 see attached fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>[subject, neon, retreat, ho, ho, ho, we, re, a...</td>\n",
       "      <td>[subject, neon, retreat, ho, ho, ho, around, w...</td>\n",
       "      <td>subject neon retreat ho ho ho around wonder ti...</td>\n",
       "      <td>subject neon retreat ho ho ho around wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>[subject, photoshop, windows, office, cheap, m...</td>\n",
       "      <td>[subject, photoshop, windows, office, cheap, m...</td>\n",
       "      <td>subject photoshop window offic cheap main tren...</td>\n",
       "      <td>subject photoshop window office cheap main tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>[subject, re, indian, springs, this, deal, is,...</td>\n",
       "      <td>[subject, indian, springs, deal, book, teco, p...</td>\n",
       "      <td>subject indian spring deal book teco pvr reven...</td>\n",
       "      <td>subject indian spring deal book teco pvr reven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num                                       text_lowered  \\\n",
       "0          0  subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1          0  subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2          0  subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3          1  subject: photoshop , windows , office . cheap ...   \n",
       "4          0  subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "                                text_punctuationfree  \\\n",
       "0  [subject, enron, methanol, meter, 988291, this...   \n",
       "1  [subject, hpl, nom, for, january, 9, 2001, see...   \n",
       "2  [subject, neon, retreat, ho, ho, ho, we, re, a...   \n",
       "3  [subject, photoshop, windows, office, cheap, m...   \n",
       "4  [subject, re, indian, springs, this, deal, is,...   \n",
       "\n",
       "                                   text_stopwordfree  \\\n",
       "0  [subject, enron, methanol, meter, 988291, foll...   \n",
       "1  [subject, hpl, nom, january, 9, 2001, see, att...   \n",
       "2  [subject, neon, retreat, ho, ho, ho, around, w...   \n",
       "3  [subject, photoshop, windows, office, cheap, m...   \n",
       "4  [subject, indian, springs, deal, book, teco, p...   \n",
       "\n",
       "                                           text_stem  \\\n",
       "0  subject enron methanol meter 988291 follow not...   \n",
       "1  subject hpl nom januari 9 2001 see attach file...   \n",
       "2  subject neon retreat ho ho ho around wonder ti...   \n",
       "3  subject photoshop window offic cheap main tren...   \n",
       "4  subject indian spring deal book teco pvr reven...   \n",
       "\n",
       "                                           text_lemm  \n",
       "0  subject enron methanol meter 988291 follow not...  \n",
       "1  subject hpl nom january 9 2001 see attached fi...  \n",
       "2  subject neon retreat ho ho ho around wonderful...  \n",
       "3  subject photoshop window office cheap main tre...  \n",
       "4  subject indian spring deal book teco pvr reven...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_lemm'] = df['text_lemm'].apply(lambda x: ' '.join([item for item in x]))\n",
    "df['text_stem'] = df['text_stem'].apply(lambda x: ' '.join([item for item in x]))\n",
    "df.drop('text',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>text_lowered</th>\n",
       "      <th>text_punctuationfree</th>\n",
       "      <th>text_stopwordfree</th>\n",
       "      <th>text_stem</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>[subject, enron, methanol, meter, 988291, this...</td>\n",
       "      <td>[subject, enron, methanol, meter, 988291, foll...</td>\n",
       "      <td>subject enron methanol meter 988291 follow not...</td>\n",
       "      <td>subject enron methanol meter 988291 follow not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>[subject, hpl, nom, for, january, 9, 2001, see...</td>\n",
       "      <td>[subject, hpl, nom, january, 9, 2001, see, att...</td>\n",
       "      <td>subject hpl nom januari 9 2001 see attach file...</td>\n",
       "      <td>subject hpl nom january 9 2001 see attached fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>[subject, neon, retreat, ho, ho, ho, we, re, a...</td>\n",
       "      <td>[subject, neon, retreat, ho, ho, ho, around, w...</td>\n",
       "      <td>subject neon retreat ho ho ho around wonder ti...</td>\n",
       "      <td>subject neon retreat ho ho ho around wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>[subject, photoshop, windows, office, cheap, m...</td>\n",
       "      <td>[subject, photoshop, windows, office, cheap, m...</td>\n",
       "      <td>subject photoshop window offic cheap main tren...</td>\n",
       "      <td>subject photoshop window office cheap main tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>[subject, re, indian, springs, this, deal, is,...</td>\n",
       "      <td>[subject, indian, springs, deal, book, teco, p...</td>\n",
       "      <td>subject indian spring deal book teco pvr reven...</td>\n",
       "      <td>subject indian spring deal book teco pvr reven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>[subject, put, the, 10, on, the, ft, the, tran...</td>\n",
       "      <td>[subject, put, 10, ft, transport, volumes, dec...</td>\n",
       "      <td>subject put 10 ft transport volum decreas 2500...</td>\n",
       "      <td>subject put 10 ft transport volume decreased 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>[subject, 3, 4, 2000, and, following, noms, hp...</td>\n",
       "      <td>[subject, 3, 4, 2000, following, noms, hpl, ta...</td>\n",
       "      <td>subject 3 4 2000 follow nom hpl take extra 15 ...</td>\n",
       "      <td>subject 3 4 2000 following noms hpl take extra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>[subject, calpine, daily, gas, nomination, jul...</td>\n",
       "      <td>[subject, calpine, daily, gas, nomination, jul...</td>\n",
       "      <td>subject calpin daili ga nomin juli mention ear...</td>\n",
       "      <td>subject calpine daily gas nomination julie men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject: industrial worksheets for august 2000...</td>\n",
       "      <td>[subject, industrial, worksheets, for, august,...</td>\n",
       "      <td>[subject, industrial, worksheets, august, 2000...</td>\n",
       "      <td>subject industri worksheet august 2000 activ a...</td>\n",
       "      <td>subject industrial worksheet august 2000 activ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>[subject, important, online, banking, alert, d...</td>\n",
       "      <td>[subject, important, online, banking, alert, d...</td>\n",
       "      <td>subject import onlin bank alert dear valu citi...</td>\n",
       "      <td>subject important online banking alert dear va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "0            605  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1           2349  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2           3624  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3           4685  Subject: photoshop , windows , office . cheap ...   \n",
       "4           2030  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "...          ...                                                ...   \n",
       "5166        1518  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
       "5167         404  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
       "5168        2933  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
       "5169        1409  Subject: industrial worksheets for august 2000...   \n",
       "5170        4807  Subject: important online banking alert\\r\\ndea...   \n",
       "\n",
       "      label_num                                       text_lowered  \\\n",
       "0             0  subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1             0  subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2             0  subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3             1  subject: photoshop , windows , office . cheap ...   \n",
       "4             0  subject: re : indian springs\\r\\nthis deal is t...   \n",
       "...         ...                                                ...   \n",
       "5166          0  subject: put the 10 on the ft\\r\\nthe transport...   \n",
       "5167          0  subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
       "5168          0  subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
       "5169          0  subject: industrial worksheets for august 2000...   \n",
       "5170          1  subject: important online banking alert\\r\\ndea...   \n",
       "\n",
       "                                   text_punctuationfree  \\\n",
       "0     [subject, enron, methanol, meter, 988291, this...   \n",
       "1     [subject, hpl, nom, for, january, 9, 2001, see...   \n",
       "2     [subject, neon, retreat, ho, ho, ho, we, re, a...   \n",
       "3     [subject, photoshop, windows, office, cheap, m...   \n",
       "4     [subject, re, indian, springs, this, deal, is,...   \n",
       "...                                                 ...   \n",
       "5166  [subject, put, the, 10, on, the, ft, the, tran...   \n",
       "5167  [subject, 3, 4, 2000, and, following, noms, hp...   \n",
       "5168  [subject, calpine, daily, gas, nomination, jul...   \n",
       "5169  [subject, industrial, worksheets, for, august,...   \n",
       "5170  [subject, important, online, banking, alert, d...   \n",
       "\n",
       "                                      text_stopwordfree  \\\n",
       "0     [subject, enron, methanol, meter, 988291, foll...   \n",
       "1     [subject, hpl, nom, january, 9, 2001, see, att...   \n",
       "2     [subject, neon, retreat, ho, ho, ho, around, w...   \n",
       "3     [subject, photoshop, windows, office, cheap, m...   \n",
       "4     [subject, indian, springs, deal, book, teco, p...   \n",
       "...                                                 ...   \n",
       "5166  [subject, put, 10, ft, transport, volumes, dec...   \n",
       "5167  [subject, 3, 4, 2000, following, noms, hpl, ta...   \n",
       "5168  [subject, calpine, daily, gas, nomination, jul...   \n",
       "5169  [subject, industrial, worksheets, august, 2000...   \n",
       "5170  [subject, important, online, banking, alert, d...   \n",
       "\n",
       "                                              text_stem  \\\n",
       "0     subject enron methanol meter 988291 follow not...   \n",
       "1     subject hpl nom januari 9 2001 see attach file...   \n",
       "2     subject neon retreat ho ho ho around wonder ti...   \n",
       "3     subject photoshop window offic cheap main tren...   \n",
       "4     subject indian spring deal book teco pvr reven...   \n",
       "...                                                 ...   \n",
       "5166  subject put 10 ft transport volum decreas 2500...   \n",
       "5167  subject 3 4 2000 follow nom hpl take extra 15 ...   \n",
       "5168  subject calpin daili ga nomin juli mention ear...   \n",
       "5169  subject industri worksheet august 2000 activ a...   \n",
       "5170  subject import onlin bank alert dear valu citi...   \n",
       "\n",
       "                                              text_lemm  \n",
       "0     subject enron methanol meter 988291 follow not...  \n",
       "1     subject hpl nom january 9 2001 see attached fi...  \n",
       "2     subject neon retreat ho ho ho around wonderful...  \n",
       "3     subject photoshop window office cheap main tre...  \n",
       "4     subject indian spring deal book teco pvr reven...  \n",
       "...                                                 ...  \n",
       "5166  subject put 10 ft transport volume decreased 2...  \n",
       "5167  subject 3 4 2000 following noms hpl take extra...  \n",
       "5168  subject calpine daily gas nomination julie men...  \n",
       "5169  subject industrial worksheet august 2000 activ...  \n",
       "5170  subject important online banking alert dear va...  \n",
       "\n",
       "[5171 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "#df['text_corrected']= df['text_lemm'].apply(lambda x: [spell.correction(word) for word in x])\n",
    "#df.head()\n",
    "#df['text_string'].apply(lambda txt: ''.join(TextBlob(txt).correct()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9871134020618557"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['label_num']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['text_lemm'])\n",
    "x_vect = vectorizer.transform(df['text_lemm'])\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x_vect,y,test_size=0.3,random_state=1153)\n",
    "\n",
    "logreg_model = logreg.fit(xtrain,ytrain)\n",
    "ytrain_pred = logreg_model.predict(xtrain)\n",
    "\n",
    "ytest_pred = logreg_model.predict(xtest)\n",
    "accuracy_score(ytest,ytest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9800257731958762"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['label_num']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "vectorizer1 = TfidfVectorizer()\n",
    "vectorizer1.fit(df['text_stem'])\n",
    "x_vect1 = vectorizer.transform(df['text_stem'])\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x_vect1,y,test_size=0.3,random_state=11434)\n",
    "\n",
    "logreg_model = logreg.fit(xtrain,ytrain)\n",
    "ytest_pred = logreg_model.predict(xtest)\n",
    "accuracy_score(ytest,ytest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9632731958762887"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['label_num']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "vectorizer2 = TfidfVectorizer()\n",
    "vectorizer2.fit(df['text_lowered'])\n",
    "x_vect2 = vectorizer.transform(df['text_lowered'])\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x_vect2,y,test_size=0.3,random_state=1153)\n",
    "\n",
    "logreg_model = logreg.fit(xtrain,ytrain)\n",
    "ytrain_pred = logreg_model.predict(xtrain)\n",
    "\n",
    "ytest_pred = logreg_model.predict(xtest)\n",
    "accuracy_score(ytest,ytest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574742268041238"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "y = df['label_num']\n",
    "\n",
    "NB = GaussianNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['text_lemm'])\n",
    "x_vect = vectorizer.transform(df['text_lemm'])\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x_vect,y,test_size=0.3,random_state=11983)\n",
    "\n",
    "NB_model = NB.fit(xtrain.toarray(),ytrain)\n",
    "ytrain_pred = NB_model.predict(xtrain.toarray())\n",
    "\n",
    "ytest_pred = NB_model.predict(xtest.toarray())\n",
    "accuracy_score(ytest,ytest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label_num']\n",
    "\n",
    "NB = GaussianNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['text_stem'])\n",
    "x_vect = vectorizer.transform(df['text_stem'])\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x_vect,y,test_size=0.3,random_state=1231)\n",
    "\n",
    "NB_model = logreg.fit(xtrain,ytrain)\n",
    "ytrain_pred = NB_model.predict(xtrain)\n",
    "\n",
    "ytest_pred = NB_model.predict(xtest)\n",
    "accuracy_score(ytest,ytest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label_num']\n",
    "\n",
    "NB = GaussianNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['text_lowered'])\n",
    "x_vect = vectorizer.transform(df['text_lowered'])\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x_vect,y,test_size=0.3,random_state=7542)\n",
    "\n",
    "NB_model = logreg.fit(xtrain,ytrain)\n",
    "ytrain_pred = NB_model.predict(xtrain)\n",
    "\n",
    "ytest_pred = NB_model.predict(xtest)\n",
    "accuracy_score(ytest,ytest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
